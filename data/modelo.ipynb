{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbfa270",
   "metadata": {},
   "source": [
    "# Notebook: Gerar 4 submissions (log1p target)\n",
    "\n",
    "Este notebook treina 4 modelos diferentes (RandomForest, GradientBoosting, XGBoost, LightGBM) aplicando `log1p` no target, faz pré-processamento automático (imputação e one-hot) e gera 4 arquivos `submission_*.csv`. Ajuste `CSV_PATH` se necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "print(\"xgboost:\", xgb.__version__)\n",
    "print(\"pandas:  \", pd.__version__)\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(\"Imports completos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c03090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Ajuste para seus paths (JA VEM PRONTO) ===\n",
    "CSV_PATH = \"/Users/augusto/Library/Mobile Documents/com~apple~CloudDocs/git/avalensurance-bia/data\"\n",
    "\n",
    "df_path = f\"{CSV_PATH}/onlyfulldata_sem_outliers_cols_especificas.csv\"\n",
    "test_path = f\"{CSV_PATH}/teste.csv\"\n",
    "\n",
    "print(\"Carregando arquivos:\")\n",
    "print(\"  treino ->\", df_path)\n",
    "print(\"  teste  ->\", test_path)\n",
    "\n",
    "df = pd.read_csv(df_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  Treino:\", df.shape)\n",
    "print(\"  Teste :\", df_test.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9461c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Preparação + log1p no target ===\n",
    "\n",
    "# Garantir que a coluna alvo é numérica\n",
    "df[\"annual_medical_cost\"] = pd.to_numeric(df[\"annual_medical_cost\"], errors=\"coerce\")\n",
    "\n",
    "# Remover registros com target inválido\n",
    "df = df.dropna(subset=[\"annual_medical_cost\"]).copy()\n",
    "\n",
    "# Remover a coluna _income_outlier_flag se existir (treino e teste)\n",
    "if \"_income_outlier_flag\" in df.columns:\n",
    "    df = df.drop(columns=[\"_income_outlier_flag\"])\n",
    "\n",
    "if \"_income_outlier_flag\" in df_test.columns:\n",
    "    df_test = df_test.drop(columns=[\"_income_outlier_flag\"])\n",
    "\n",
    "# Aplicar log1p no target\n",
    "y = np.log1p(df[\"annual_medical_cost\"])\n",
    "\n",
    "# X = tudo exceto o target\n",
    "X = df.drop(columns=[\"annual_medical_cost\"])\n",
    "X_test = df_test.copy()\n",
    "\n",
    "# Separar tipos de colunas\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "\n",
    "print(f\"Numéricas: {len(num_cols)} | Categóricas: {len(cat_cols)}\")\n",
    "print(\"Exemplos de colunas numéricas:\", num_cols[:10])\n",
    "print(\"Exemplos de colunas categóricas:\", cat_cols[:10])\n",
    "\n",
    "# Pré-processamento\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"__missing__\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Pré-processador criado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_export(model, name, X=X, y=y, X_test=df_test, preprocessor=preprocessor, out_dir='.'):\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    print(f\"\\nTreinando modelo: {name} ...\")\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    print(\"Gerando previsões...\")\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    # desfaz log1p\n",
    "    preds = np.expm1(preds)\n",
    "\n",
    "    # proteção contra negativos / NaN\n",
    "    preds = np.clip(preds, 0, None)\n",
    "    preds = np.nan_to_num(preds, nan=0)\n",
    "\n",
    "    # ⚠️ Garanta que person_id exista no df_test\n",
    "    if \"person_id\" not in X_test.columns:\n",
    "        raise KeyError(\"A coluna 'person_id' não existe no arquivo de teste!\")\n",
    "\n",
    "    # gerar dataframe final conforme Kaggle espera\n",
    "    submission = pd.DataFrame({\n",
    "        \"person_id\": X_test[\"person_id\"].values,\n",
    "        \"annual_medical_cost\": preds\n",
    "    })\n",
    "\n",
    "    out_path = os.path.join(out_dir, f\"submission_{name}.csv\")\n",
    "    submission.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"✔ Arquivo salvo -> {out_path}\")\n",
    "    return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2241d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitua apenas o bloco que chama train_and_export para o XGBoost por este\n",
    "try:\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=1200,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1,\n",
    "        enable_categorical=False   # <-- correção aqui\n",
    "    )\n",
    "    train_and_export(xgb_model, \"xgb_fixed\")\n",
    "except Exception as e:\n",
    "    print(\"Falhou ao treinar XGBoost com correção. Erro:\", e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c347d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 — Random Forest\n",
    "train_and_export(\n",
    "    RandomForestRegressor(\n",
    "        n_estimators=600,\n",
    "        max_depth=15,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"rf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e21d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 — Gradient Boosting\n",
    "train_and_export(\n",
    "    GradientBoostingRegressor(\n",
    "        learning_rate=0.03,\n",
    "        n_estimators=800,\n",
    "        max_depth=4,\n",
    "        subsample=0.9,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"gb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efae719",
   "metadata": {},
   "outputs": [],
   "source": [
    " #4 — LightGBM\n",
    "train_and_export(\n",
    "    lgb.LGBMRegressor(\n",
    "        n_estimators=1500,\n",
    "        learning_rate=0.015,\n",
    "        max_depth=-1,\n",
    "        num_leaves=40,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"lgbm\"\n",
    ")\n",
    "\n",
    "print(\"\\nTodos os modelos treinados e arquivos gerados (se possível).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a7858",
   "metadata": {},
   "source": [
    "## Observações\n",
    "\n",
    "- Se faltar alguma dependência, instale com `pip install xgboost lightgbm`.\n",
    "- Ajuste `CSV_PATH` se seus arquivos estiverem em outro local.\n",
    "- Se quiser que eu gere também um stacking ou faça tuning com Optuna, me avisa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
