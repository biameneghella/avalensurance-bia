{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# === Caminhos (ajuste se necessário) ===\n",
    "df_path = \"onlyfulldata_sem_outliers_cols_especificas.csv\"\n",
    "test_path = \"teste.csv\"\n",
    "\n",
    "# === Carregar dados ===\n",
    "df = pd.read_csv(df_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# === Remover registros sem custo (já fazia) ===\n",
    "df = df.dropna(subset=[\"annual_medical_cost\"]).copy()\n",
    "\n",
    "# === Inspeciona valores problemáticos em annual_medical_cost ===\n",
    "print(\"Resumo annual_medical_cost — count/min/max/mean:\")\n",
    "print(df[\"annual_medical_cost\"].describe())\n",
    "\n",
    "# Linhas com valores <= -1 (causam log1p -> -inf) ou valores negativos fora do esperado\n",
    "bad_mask = df[\"annual_medical_cost\"] <= -1\n",
    "if bad_mask.any():\n",
    "    print(f\"\\nEncontradas {bad_mask.sum()} linhas com annual_medical_cost <= -1 (problemáticas para log1p). Exemplo:\")\n",
    "    print(df.loc[bad_mask, [\"annual_medical_cost\"]].head(10))\n",
    "else:\n",
    "    print(\"\\nNenhuma linha com annual_medical_cost <= -1 encontrada.\")\n",
    "\n",
    "# --- Escolha de tratamento: aqui vamos remover valores negativos/invalidos (ajuste se preferir outra lógica)\n",
    "# Mantemos custos >= 0 (log1p(0)=0 é válido). Se preferir manter zeros mas investigar negativos, ajuste aqui.\n",
    "df = df[df[\"annual_medical_cost\"] >= 0].copy()\n",
    "print(\"\\nApós filtro (mantendo annual_medical_cost >= 0):\", df.shape)\n",
    "\n",
    "# === Remover colunas de ID (não informativas para modelo) ===\n",
    "id_cols = [\"person_id\", \"cost_id\", \"policy_id\", \"record_id\", \"visit_id\"]\n",
    "df = df.drop(columns=[col for col in id_cols if col in df.columns])\n",
    "\n",
    "# === Criar coluna alvo com log1p (safety: agora não haverá -inf) ===\n",
    "df[\"annual_medical_cost_log\"] = np.log1p(df[\"annual_medical_cost\"])\n",
    "\n",
    "# === Separar features numéricas e categóricas ===\n",
    "categorical = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "numerical = df.select_dtypes(include=np.number).drop(columns=[\"annual_medical_cost\", \"annual_medical_cost_log\"], errors=\"ignore\").columns.tolist()\n",
    "\n",
    "print(\"Numéricas:\", len(numerical), \"— Exemplo:\", numerical[:10])\n",
    "print(\"Categóricas:\", len(categorical), \"— Exemplo:\", categorical[:10])\n",
    "\n",
    "# === Tratar dtypes 'nullable' (Int64, boolean, UInt...) convertendo para float ===\n",
    "nullable_cols = [c for c in df.columns if str(df[c].dtype).startswith((\"Int64\",\"boolean\",\"UInt\"))]\n",
    "if nullable_cols:\n",
    "    print(\"Convertendo colunas 'nullable' para float:\", nullable_cols)\n",
    "    for c in nullable_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(float)\n",
    "        if c in df_test.columns:\n",
    "            df_test[c] = pd.to_numeric(df_test[c], errors=\"coerce\").astype(float)\n",
    "    categorical = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "    numerical = df.select_dtypes(include=np.number).drop(columns=[\"annual_medical_cost\", \"annual_medical_cost_log\"], errors=\"ignore\").columns.tolist()\n",
    "\n",
    "# === Pré-processamento ===\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numerical),\n",
    "    (\"cat\", categorical_transformer, categorical)\n",
    "], sparse_threshold=0.3)\n",
    "\n",
    "# === Modelo (XGBoost) ===\n",
    "model = XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "# Função para forçar float32 (evita dtypes object/nullable chegando ao XGBoost)\n",
    "to_float32 = FunctionTransformer(lambda X: X.astype(np.float32), validate=False)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preproc\", preprocessor),\n",
    "    (\"to_float32\", to_float32),\n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "# === Treino (pre-fit checks) ===\n",
    "X_train = df.drop(columns=[\"annual_medical_cost\", \"annual_medical_cost_log\"]).copy()\n",
    "y_train = df[\"annual_medical_cost_log\"].copy()\n",
    "\n",
    "print(\"\\n>>> Checando dtypes originais (train):\")\n",
    "print(X_train.dtypes.value_counts())\n",
    "print(\"\\nNaNs em y_train (deve ser 0):\", y_train.isna().sum())\n",
    "print(\"min/max y_train:\", y_train.min(), y_train.max())\n",
    "\n",
    "# Testar preprocessor separadamente (debug)\n",
    "preproc = preprocessor.fit(X_train)\n",
    "X_train_trans = preproc.transform(X_train)\n",
    "print(\"\\nSaída do preprocessor:\", type(X_train_trans))\n",
    "if sp.issparse(X_train_trans):\n",
    "    print(\"Sparse matrix — shape:\", X_train_trans.shape, \"nnz:\", X_train_trans.nnz)\n",
    "else:\n",
    "    print(\"Numpy array — shape:\", X_train_trans.shape, \"dtype:\", X_train_trans.dtype)\n",
    "    print(\"contains NaN:\", np.isnan(X_train_trans).any(), \"contains inf:\", np.isinf(X_train_trans).any())\n",
    "\n",
    "# Treinando pipeline completa\n",
    "print(\"\\nTreinando pipeline completo...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"✅ pipeline.fit() completado com sucesso\")\n",
    "\n",
    "# === Teste / Preparo X_test ===\n",
    "X_test = df_test.copy()\n",
    "ids = X_test[\"person_id\"] if \"person_id\" in X_test.columns else np.arange(len(X_test))\n",
    "X_test = X_test.drop(columns=[\"person_id\"], errors=\"ignore\")\n",
    "\n",
    "# Garante que X_test tenha todas as colunas do treino\n",
    "for col in X_train.columns:\n",
    "    if col not in X_test.columns:\n",
    "        X_test[col] = np.nan\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# Forçar tipos básicos em X_test:\n",
    "for c in numerical:\n",
    "    if c in X_test.columns:\n",
    "        X_test[c] = pd.to_numeric(X_test[c], errors=\"coerce\")\n",
    "for c in categorical:\n",
    "    if c in X_test.columns:\n",
    "        X_test[c] = X_test[c].astype(object)\n",
    "\n",
    "print(\"\\nDtypes X_test (resumo):\")\n",
    "print(X_test.dtypes.value_counts())\n",
    "\n",
    "# === Predição ===\n",
    "print(\"\\nRealizando predições...\")\n",
    "y_pred_log = pipeline.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "# === Submissão ===\n",
    "submission = pd.DataFrame({\n",
    "    \"person_id\": ids,\n",
    "    \"annual_medical_cost\": y_pred\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"✅ Submissão salva com sucesso em 'submission.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
