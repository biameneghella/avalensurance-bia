{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7386e986",
   "metadata": {},
   "source": [
    "# Limpeza — demographics.csv \n",
    "esse caderno, por enquanto, apenas organiza em ordem crescente as informações, e retira duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84526c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV_PATH: /Users/augusto/Library/Mobile Documents/com~apple~CloudDocs/git/avalensurance-bia/data/demographics.csv\n",
      "Existe o arquivo? True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# (ajuste para o seu usuário/sistema):\n",
    "CSV_PATH = Path(\"/Users/augusto/Library/Mobile Documents/com~apple~CloudDocs/git/avalensurance-bia/data/demographics.csv\")\n",
    "\n",
    "\n",
    "print(\"CSV_PATH:\", CSV_PATH)\n",
    "print(\"Existe o arquivo?\", CSV_PATH.exists())\n",
    "if not CSV_PATH.exists():\n",
    "    raise FileNotFoundError(\"Arquivo não encontrado. Edite CSV_PATH acima e rode novamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1197236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão inicial (linhas, colunas): (71280, 11)\n",
      "Duplicatas exatas removidas: 6480 (de 71280 → 64800)\n",
      "[LIMPEZA AGE] Linhas com age alterado para -1: 2411\n",
      "✅ CSV limpo salvo em: /Users/augusto/Library/Mobile Documents/com~apple~CloudDocs/git/avalensurance-bia/data/demographics_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Dimensão inicial (linhas, colunas):\", df.shape)\n",
    "\n",
    "if \"person_id\" not in df.columns:\n",
    "    raise ValueError(\"A coluna 'person_id' não existe no CSV.\")\n",
    "\n",
    "# Preenchimentos padrão\n",
    "fill_na = {\n",
    "    \"person_id\": -1,\n",
    "    \"age\": -1,\n",
    "    \"income\": -1,\n",
    "    \"household_size\": -1,\n",
    "    \"dependents\": -1,\n",
    "}\n",
    "for col, val in fill_na.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(val)\n",
    "\n",
    "for cat_col in [\"sex\",\"region\",\"urban_rural\",\"education\",\"marital_status\",\"employment_status\"]:\n",
    "    if cat_col in df.columns:\n",
    "        df[cat_col] = df[cat_col].replace(\"\", pd.NA).fillna(\"no_data\")\n",
    "\n",
    "# =========================\n",
    "# 2️⃣ Ordenar por person_id e remover duplicatas\n",
    "# =========================\n",
    "\n",
    "pid_num = pd.to_numeric(df[\"person_id\"], errors=\"coerce\")\n",
    "df = (\n",
    "    df.assign(_pid_num=pid_num, _pid_str=df[\"person_id\"].astype(str))\n",
    "      .sort_values(by=[\"_pid_num\", \"_pid_str\"], kind=\"mergesort\", na_position=\"last\")\n",
    "      .drop(columns=[\"_pid_num\", \"_pid_str\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "before = len(df)\n",
    "df = df.drop_duplicates(keep=\"first\")\n",
    "after = len(df)\n",
    "print(f\"Duplicatas exatas removidas: {before - after} (de {before} → {after})\")\n",
    "\n",
    "# =========================\n",
    "# 3️⃣ Normalização e validação de domínios\n",
    "# =========================\n",
    "\n",
    "def _norm_token(x):\n",
    "    if pd.isna(x): return \"no_data\"\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in {\"na\",\"n/a\",\"none\",\"null\",\"no data\",\"sem dado\"}:\n",
    "        return \"no_data\"\n",
    "    return s\n",
    "\n",
    "def normalize_categorical(series, mapping, allowed):\n",
    "    s = series.map(_norm_token)\n",
    "    def map_to_canon(v):\n",
    "        if v == \"no_data\": return \"no_data\"\n",
    "        key = v.lower()\n",
    "        return mapping.get(key, v)\n",
    "    s = s.map(map_to_canon)\n",
    "    s = s.where(s.isin(allowed | {\"no_data\"}), \"no_data\")\n",
    "    return s\n",
    "\n",
    "# Mapas e domínios\n",
    "sex_map = {\"male\":\"Male\",\"m\":\"Male\",\"female\":\"Female\",\"f\":\"Female\"}\n",
    "sex_allowed = {\"Male\",\"Female\"}\n",
    "region_map = {\"north\":\"North\",\"south\":\"South\",\"east\":\"East\",\"west\":\"West\",\"central\":\"Central\"}\n",
    "region_allowed = {\"North\",\"South\",\"East\",\"West\",\"Central\"}\n",
    "urban_map = {\"urban\":\"Urban\",\"rural\":\"Rural\",\"suburban\":\"Suburban\"}\n",
    "urban_allowed = {\"Urban\",\"Rural\",\"Suburban\"}\n",
    "edu_map = {\"no hs\":\"No HS\",\"hs\":\"HS\",\"high school\":\"HS\",\"some college\":\"Some College\",\"bachelors\":\"Bachelors\",\"masters\":\"Masters\",\"doctorate\":\"Doctorate\",\"phd\":\"Doctorate\"}\n",
    "edu_allowed = {\"No HS\",\"HS\",\"Some College\",\"Bachelors\",\"Masters\",\"Doctorate\"}\n",
    "marital_map = {\"single\":\"Single\",\"married\":\"Married\",\"divorced\":\"Divorced\",\"widowed\":\"Widowed\"}\n",
    "marital_allowed = {\"Single\",\"Married\",\"Divorced\",\"Widowed\"}\n",
    "emp_map = {\"employed\":\"Employed\",\"unemployed\":\"Unemployed\",\"self-employed\":\"Self-employed\",\"self employed\":\"Self-employed\",\"retired\":\"Retired\"}\n",
    "emp_allowed = {\"Employed\",\"Unemployed\",\"Self-employed\",\"Retired\"}\n",
    "\n",
    "# Aplicar\n",
    "for col, mapping, allowed in [\n",
    "    (\"sex\", sex_map, sex_allowed),\n",
    "    (\"region\", region_map, region_allowed),\n",
    "    (\"urban_rural\", urban_map, urban_allowed),\n",
    "    (\"education\", edu_map, edu_allowed),\n",
    "    (\"marital_status\", marital_map, marital_allowed),\n",
    "    (\"employment_status\", emp_map, emp_allowed),\n",
    "]:\n",
    "    if col in df.columns:\n",
    "        df[col] = normalize_categorical(df[col], mapping, allowed)\n",
    "\n",
    "# =========================\n",
    "# 4️⃣ Regras para AGE\n",
    "# =========================\n",
    "\n",
    "age = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "age_valid = age.where(age >= 0)\n",
    "\n",
    "edu = df[\"education\"].fillna(\"no_data\")\n",
    "emp = df[\"employment_status\"].fillna(\"no_data\")\n",
    "\n",
    "invalid_mask = (age_valid < 13) | (age_valid > 85)\n",
    "\n",
    "age_13_15 = (age_valid >= 13) & (age_valid <= 15)\n",
    "age_16_17 = (age_valid >= 16) & (age_valid <= 17)\n",
    "age_18_20 = (age_valid >= 18) & (age_valid <= 20)\n",
    "\n",
    "edu_ok_13_15 = {\"No HS\",\"HS\"}\n",
    "edu_ok_16_17 = {\"No HS\",\"HS\"}\n",
    "edu_mismatch_13_15 = age_13_15 & (~edu.isin(edu_ok_13_15)) & (edu != \"no_data\")\n",
    "edu_mismatch_16_17 = age_16_17 & (~edu.isin(edu_ok_16_17)) & (edu != \"no_data\")\n",
    "edu_mismatch_18_20 = age_18_20 & (edu.isin({\"Masters\",\"Doctorate\"}))\n",
    "\n",
    "emp_bad_13_15 = {\"Employed\",\"Self-employed\",\"Retired\"}\n",
    "emp_bad_16_17 = {\"Self-employed\",\"Retired\"}\n",
    "emp_bad_18_20 = {\"Retired\"}\n",
    "emp_mismatch_13_15 = age_13_15 & (emp.isin(emp_bad_13_15))\n",
    "emp_mismatch_16_17 = age_16_17 & (emp.isin(emp_bad_16_17))\n",
    "emp_mismatch_18_20 = age_18_20 & (emp.isin(emp_bad_18_20))\n",
    "\n",
    "teen_inconsistent = (\n",
    "    edu_mismatch_13_15 | edu_mismatch_16_17 | edu_mismatch_18_20 |\n",
    "    emp_mismatch_13_15 | emp_mismatch_16_17 | emp_mismatch_18_20\n",
    ")\n",
    "\n",
    "df.loc[invalid_mask | teen_inconsistent, \"age\"] = -1\n",
    "\n",
    "print(f\"[LIMPEZA AGE] Linhas com age alterado para -1: {(invalid_mask | teen_inconsistent).sum()}\")\n",
    "\n",
    "# =========================\n",
    "# 5️⃣ Consistência household_size × dependents\n",
    "# =========================\n",
    "\n",
    "hh = pd.to_numeric(df[\"household_size\"], errors=\"coerce\")\n",
    "dep = pd.to_numeric(df[\"dependents\"], errors=\"coerce\")\n",
    "\n",
    "issue_hh = (hh.isna()) | (hh < 1) | (hh % 1 != 0)\n",
    "issue_dep = (dep.isna()) | (dep < 0) | (dep % 1 != 0)\n",
    "issue_dep_gt = (hh.notna()) & (dep.notna()) & (dep > (hh - 1))\n",
    "\n",
    "df.loc[issue_hh, \"household_size\"] = -1\n",
    "df.loc[issue_dep | issue_dep_gt, \"dependents\"] = -1\n",
    "\n",
    "# =========================\n",
    "# 6️⃣ Limpeza de income (manter -1 para ausentes; outlier flag em válidos)\n",
    "# =========================\n",
    "\n",
    "# 1) Garantir que income final mantenha -1 para ausentes\n",
    "inc_raw = pd.to_numeric(df[\"income\"], errors=\"coerce\")\n",
    "df[\"income\"] = inc_raw.fillna(-1)\n",
    "\n",
    "# 2) Criar série de trabalho somente com valores válidos (>= 0) para estatística\n",
    "inc_valid = inc_raw.where(inc_raw >= 0, np.nan)\n",
    "\n",
    "# 3) Outliers por IQR com base nos válidos\n",
    "q1, q3 = inc_valid.quantile(0.25), inc_valid.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "upper = q3 + 1.5 * iqr\n",
    "lower = q1 - 1.5 * iqr\n",
    "\n",
    "outlier_flag = (inc_valid < lower) | (inc_valid > upper)\n",
    "df[\"_income_outlier_flag\"] = outlier_flag.fillna(False).astype(int)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 7️⃣ Salvar arquivos de saída\n",
    "# =========================\n",
    "\n",
    "repo_dir = CSV_PATH.parent.parent\n",
    "out_clean = repo_dir / \"data\" / \"demographics_cleaned.csv\"\n",
    "\n",
    "out_clean.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(out_clean, index=False)\n",
    "print(\"✅ CSV limpo salvo em:\", out_clean)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
